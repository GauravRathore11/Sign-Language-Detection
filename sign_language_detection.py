# -*- coding: utf-8 -*-
"""sign language detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YvQ6WDR9Q2D18CQcF_65FJkytR5fGIVs
"""

!nvidia-smi

!pip install ultralytics

from ultralytics import YOLO

model = YOLO()

model.train(data="/content/drive/MyDrive/sign_language_dataset/data.yaml",epochs=50) #train the model

import os
import locale

# List contents of /content directory
content_files = os.listdir('/content')

# List contents of /content/runs/train directory
# List contents of the /content/runs directory
runs_files = os.listdir('/content/runs/detect')
print(runs_files)

# Set locale to UTF-8
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding

!cp -r /content/runs /content/drive/MyDrive/sign_language_dataset/yolov8_training_results

!yolo task=detect mode=val model='/content/drive/MyDrive/sign_language_dataset/yolov8_training_results/detect/train2/weights/best.pt' data='/content/drive/MyDrive/sign_language_dataset/data.yaml'

!cp -r /content/runs/detect/val /content/drive/MyDrive/sign_language_dataset/yolov8_training_results/detect/val

!yolo task=detect mode=predict model="/content/drive/MyDrive/sign_language_dataset/yolov8_training_results/detect/train2/weights/best.pt" data='/content/drive/MyDrive/sign_language_dataset/test/images'

!cp -r /content/runs/detect/predict /content/drive/MyDrive/sign_language_dataset/yolov8_training_results/detect/predict

pip install gradio matplotlib

import ultralytics
import gradio as gr
from ultralytics import YOLO
from PIL import Image
import numpy as np

# Load your trained model
model = YOLO('/content/drive/MyDrive/sign_language_dataset/yolov8_training_results/detect/train2/weights/best.pt')


def predict_image(image):
    # Check if image is a PIL Image, and if so, convert it to a numpy array
    if isinstance(image, Image.Image):
        image = np.array(image)  # Convert PIL image to numpy array

    # Perform YOLO model prediction
    results = model(image)

    # Render results and return the image with annotations
    annotated_image = results[0].plot()  # Using plot() instead of render() to avoid potential errors

    # Convert numpy array back to PIL image for Gradio output
    annotated_image = Image.fromarray(annotated_image)

    return annotated_image  # Return the annotated image


# Create Gradio Interface
interface = gr.Interface(
    fn=predict_image,  # Function for predictions
    inputs=gr.Image(type="pil"),  # Input type (image uploaded via Gradio)
    outputs=gr.Image(type="pil"),  # Output type (image with annotations)
    title="YOLO Image Prediction",
    description="Upload an image to get object detection results using YOLO."
)

# Launch the interface
interface.launch()

import cv2
from moviepy.editor import VideoFileClip

def predict_video(video_path):
    # Open video using VideoFileClip (or use OpenCV's cv2.VideoCapture for real-time)
    clip = VideoFileClip(video_path)

    # List to store annotated frames
    annotated_frames = []

    # Iterate over each frame in the video
    for frame in clip.iter_frames():
        # Convert the frame (numpy array) to RGB if necessary
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Perform YOLO model prediction
        results = model(frame)

        # Annotate the frame (use plot or render as needed)
        annotated_frame = results[0].plot()

        # Convert back to BGR for video saving (if necessary)
        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)

        # Append annotated frame
        annotated_frames.append(annotated_frame)

    # Write the annotated frames back into a video file using OpenCV
    height, width, _ = annotated_frames[0].shape
    out = cv2.VideoWriter('output_annotated.mp4', cv2.VideoWriter_fourcc(*'mp4v'), clip.fps, (width, height))

    for frame in annotated_frames:
        out.write(frame)

    out.release()

    return 'output_annotated.mp4'  # Return the path to the annotated video file

# Create Gradio Interface
interface = gr.Interface(
    fn=predict_video,  # Function for predictions
    inputs=gr.Video(),  # Input type (video uploaded via Gradio)
    outputs=gr.Video(),  # Output type (video with annotations)
    title="YOLO Video Prediction",
    description="Upload a video to get object detection results using YOLO."
)

# Launch the interface
interface.launch()